[
  {
    "objectID": "notebooks/Untitled.html",
    "href": "notebooks/Untitled.html",
    "title": "BCI Movement Decoding",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport pandas as pd\n\ndf = pd.read_csv(\"../assets/BCIsensor_xy.csv\", header=None)\nx = df.iloc[:, 0]\ny = df.iloc[:, 1]\nplt.plot(x, y)\nplt.scatter(x, y, color=\"blue\", s=20, zorder=3)\nfor i, (xi, yi) in enumerate(zip(x, y)):\n        plt.text(xi, yi, str(i + 1), fontsize=8, ha='right', va='bottom')\nplt.axis(\"equal\")\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# bci_analysis.py\n# Integrated script for BCI Movement Decoding Mini-Project #2 (ECE 580)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import griddata\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, roc_curve, auc\nimport time # To time the execution\n\nprint(\"--- BCI Movement Decoding Analysis Script ---\")\n\n# === 1. Data Loading Functions ===\n\ndef load_and_prepare_data(file1, file2, label1=0, label2=1):\n    \"\"\"\n    Loads feature data from two CSV files (class 1 and class 2),\n    transposes if necessary (assuming features=rows, trials=cols in CSV),\n    assigns labels, and concatenates.\n\n    Args:\n        file1 (str): Path to CSV file for class 1.\n        file2 (str): Path to CSV file for class 2.\n        label1 (int): Label for class 1.\n        label2 (int): Label for class 2.\n\n    Returns:\n        tuple: (X, y) numpy arrays for features and labels.\n               Returns (None, None) on error.\n    \"\"\"\n    print(f\"Loading data: {file1} (Label {label1}), {file2} (Label {label2})\")\n    try:\n        # Assumes CSVs have features as rows (204), trials as columns (120)\n        # Transpose (.T) to get trials as rows, features as columns\n        df1 = pd.read_csv(file1, header=None).T\n        df2 = pd.read_csv(file2, header=None).T\n\n        if df1.shape[1] != 204 or df2.shape[1] != 204:\n             print(f\"Warning: Expected 204 features (columns after transpose). Got {df1.shape[1]} and {df2.shape[1]}. Check CSV format.\")\n\n        y1 = np.full(df1.shape[0], label1)\n        y2 = np.full(df2.shape[0], label2)\n\n        X = pd.concat([df1, df2], ignore_index=True).values\n        y = np.concatenate([y1, y2])\n        print(f\"Data loaded successfully. X shape: {X.shape}, y shape: {y.shape}\")\n        return X, y\n    except FileNotFoundError as e:\n        print(f\"Error: File not found - {e}. Cannot load data.\")\n        return None, None\n    except Exception as e:\n        print(f\"Error loading data files: {e}\")\n        return None, None\n\ndef load_sensor_locations(filename=\"BCIsensor_xy.csv\"):\n    \"\"\"Loads sensor locations (102 electrodes) from the specified CSV file.\"\"\"\n    print(f\"Loading sensor locations from: {filename}\")\n    try:\n        # Assumes 2 columns (x, y), no header\n        locations = pd.read_csv(filename, header=None, names=['x', 'y']).values\n        if locations.shape[0] != 102 or locations.shape[1] != 2:\n            print(f\"Warning: Expected 102x2 shape for sensor locations, but got {locations.shape}. Check file '{filename}'.\")\n        print(f\"Sensor locations loaded. Shape: {locations.shape}\")\n        return locations[:, 0], locations[:, 1] # Return x and y coordinates\n    except FileNotFoundError:\n        print(f\"Error: Sensor location file '{filename}' not found.\")\n        return None, None\n    except Exception as e:\n        print(f\"Error loading sensor locations from '{filename}': {e}\")\n        return None, None\n\n# === 2. Core Two-Level Cross-Validation Function ===\n\ndef perform_two_level_cv(X, y, data_label=\"Data\", outer_k=6, inner_k=5):\n    \"\"\"\n    Performs two-level stratified cross-validation for SVM linear kernel.\n    Tunes hyperparameter C based on inner CV accuracy.\n    Collects accuracy, decision scores, and fold 1 coefficients.\n\n    Args:\n        X (np.array): Feature matrix (samples x features).\n        y (np.array): Label vector.\n        data_label (str): Label for the dataset type (e.g., \"Overt\", \"Imagined\") for printing.\n        outer_k (int): Number of outer folds.\n        inner_k (int): Number of inner folds.\n\n    Returns:\n        dict: A dictionary containing results:\n              'avg_accuracy', 'std_accuracy', 'optimal_Cs', 'fold_accuracies',\n              'all_true_labels', 'all_decision_scores', 'fold1_coefficients',\n              'outer_fold_true_labels', 'outer_fold_scores'\n              Returns None on error.\n    \"\"\"\n    if X is None or y is None:\n        print(f\"Error: Missing input data (X or y) for CV on {data_label}.\")\n        return None\n\n    # Ensure C_range covers C values corresponding to required alpha={0.01, 1, 100, 10000}\n    # C ~ {100, 1, 0.01, 0.0001}\n    C_range = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] # Example range covering requirements\n\n    outer_cv = StratifiedKFold(n_splits=outer_k, shuffle=True, random_state=42)\n    inner_cv = StratifiedKFold(n_splits=inner_k, shuffle=True, random_state=42) # Use different random_state? Usually not needed.\n\n    # Initialization for storing results\n    outer_fold_accuracies = []\n    optimal_Cs = []\n    all_true_labels = []\n    all_decision_scores = []\n    outer_fold_true_labels = [] # List of arrays per fold\n    outer_fold_scores = []      # List of arrays per fold\n    fold1_coefficients = None\n\n    print(f\"\\n--- Starting {outer_k}-Fold Outer CV for {data_label} Data ---\")\n    start_time_cv = time.time()\n\n    # Outer loop\n    for i, (train_outer_idx, test_outer_idx) in enumerate(outer_cv.split(X, y)):\n        fold_start_time = time.time()\n        print(f\"  Outer Fold {i+1}/{outer_k}\")\n        X_train_outer, X_test_outer = X[train_outer_idx], X[test_outer_idx]\n        y_train_outer, y_test_outer = y[train_outer_idx], y[test_outer_idx]\n\n        # Data Scaling (Outer Fold)\n        scaler = StandardScaler()\n        X_train_outer_scaled = scaler.fit_transform(X_train_outer)\n        X_test_outer_scaled = scaler.transform(X_test_outer)\n\n        inner_loop_results = {}\n\n        # Inner loop for hyperparameter tuning (finding best C)\n        # print(f\"    Starting {inner_k}-fold inner CV...\") # Less verbose\n        best_inner_acc = -1\n        best_C_for_fold = C_range[0] # Default to first C\n\n        for C_val in C_range:\n            inner_fold_accuracies = []\n            for j, (train_inner_idx, val_inner_idx) in enumerate(inner_cv.split(X_train_outer_scaled, y_train_outer)):\n                X_train_inner, X_val_inner = X_train_outer_scaled[train_inner_idx], X_train_outer_scaled[val_inner_idx]\n                y_train_inner, y_val_inner = y_train_outer[train_inner_idx], y_train_outer[val_inner_idx]\n\n                svm_inner = SVC(kernel='linear', C=C_val, random_state=42, probability=False)\n                svm_inner.fit(X_train_inner, y_train_inner)\n                accuracy = svm_inner.score(X_val_inner, y_val_inner)\n                inner_fold_accuracies.append(accuracy)\n\n            avg_inner_acc = np.mean(inner_fold_accuracies)\n            inner_loop_results[C_val] = avg_inner_acc\n            if avg_inner_acc &gt; best_inner_acc:\n                best_inner_acc = avg_inner_acc\n                best_C_for_fold = C_val\n\n        optimal_Cs.append(best_C_for_fold)\n        # print(f\"    Optimal C found: {best_C_for_fold} (Avg Inner Acc: {best_inner_acc:.4f})\")\n\n        # Train final SVM for this outer fold\n        # print(f\"    Training final SVM with C={best_C_for_fold}...\")\n        final_svm = SVC(kernel='linear', C=best_C_for_fold, random_state=42)\n        final_svm.fit(X_train_outer_scaled, y_train_outer)\n\n        # Evaluate final SVM\n        outer_accuracy = final_svm.score(X_test_outer_scaled, y_test_outer)\n        outer_fold_accuracies.append(outer_accuracy)\n        decision_scores = final_svm.decision_function(X_test_outer_scaled)\n\n        # Store results for overall metrics and per-fold ROC\n        all_true_labels.extend(y_test_outer)\n        all_decision_scores.extend(decision_scores)\n        outer_fold_true_labels.append(y_test_outer) # Store labels for this fold\n        outer_fold_scores.append(decision_scores)   # Store scores for this fold\n\n        # Store Fold 1 coefficients\n        if i == 0:\n            fold1_coefficients = final_svm.coef_.flatten()\n\n        fold_end_time = time.time()\n        print(f\"  Outer Fold {i+1} completed. Accuracy: {outer_accuracy:.4f}. Optimal C: {best_C_for_fold}. Time: {fold_end_time - fold_start_time:.1f}s\")\n\n    # --- End Outer Loop ---\n    end_time_cv = time.time()\n    average_accuracy = np.mean(outer_fold_accuracies)\n    std_dev_accuracy = np.std(outer_fold_accuracies)\n\n    print(f\"\\nFinished {outer_k}-fold CV for {data_label} data.\")\n    print(f\"Total CV Time: {end_time_cv - start_time_cv:.1f}s\")\n    print(f\"Optimal C found per fold: {optimal_Cs}\")\n    print(f\"Accuracy per fold: {[f'{acc:.4f}' for acc in outer_fold_accuracies]}\")\n    print(f\"Average Accuracy: {average_accuracy:.4f} +/- {std_dev_accuracy:.4f}\")\n\n    results = {\n        'avg_accuracy': average_accuracy,\n        'std_accuracy': std_dev_accuracy,\n        'optimal_Cs': optimal_Cs,\n        'fold_accuracies': outer_fold_accuracies,\n        'all_true_labels': np.array(all_true_labels),\n        'all_decision_scores': np.array(all_decision_scores),\n        'fold1_coefficients': fold1_coefficients,\n        'outer_fold_true_labels': outer_fold_true_labels, # List of arrays\n        'outer_fold_scores': outer_fold_scores           # List of arrays\n    }\n    return results\n\n\n# === 3. Plotting Functions ===\n\ndef plot_svm_weights_stem(weights, title=\"SVM Channel Weights (Fold 1)\", top_n=6):\n    \"\"\"Generates a stem plot of SVM weights, highlighting top N.\"\"\"\n    if weights is None or len(weights) == 0:\n        print(\"Error: No weights provided for stem plot.\")\n        return\n\n    n_channels = len(weights)\n    channel_indices = np.arange(1, n_channels + 1)\n    dominant_indices = np.argsort(np.abs(weights))[-top_n:]\n\n    plt.figure(figsize=(12, 6))\n    markerline, stemlines, baseline = plt.stem(channel_indices, weights, linefmt='grey', markerfmt='o', basefmt='r-', label='_nolegend_')\n    plt.setp(markerline, markersize=4, markerfacecolor='grey', markeredgecolor='black')\n\n    # Highlight dominant channels and add text\n    for idx in dominant_indices:\n        plt.stem(channel_indices[idx], weights[idx], linefmt='b-', markerfmt='bo', basefmt=' ') # Avoid redrawing baseline\n        plt.text(channel_indices[idx], weights[idx] + 0.05 * np.sign(weights[idx]), f'{weights[idx]:.2f}',\n                 ha='center', va='bottom', color='blue', fontsize=9)\n\n    # Create a proxy artist for the legend\n    dominant_proxy = plt.Line2D([0], [0], linestyle='none', c='b', marker='o', markersize=5, label=f'Top {top_n} Dominant Channels')\n\n    plt.xlabel(\"Channel Index\")\n    plt.ylabel(\"SVM Weight\")\n    plt.title(title)\n    plt.xlim(0, n_channels + 1)\n    plt.legend(handles=[dominant_proxy])\n    plt.grid(True, axis='y', linestyle=':')\n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_weights_on_brain(weights, sensor_x, sensor_y, title=\"SVM Weight Magnitude on Brain Surface (Fold 1)\", grid_resolution=100):\n    \"\"\"Visualizes SVM weight magnitude interpolated on the brain surface.\"\"\"\n    if weights is None or len(weights) != 204:\n        print(\"Error: Expected 204 weights for brain plot.\")\n        return\n    if sensor_x is None or sensor_y is None or len(sensor_x) != 102 or len(sensor_y) != 102:\n        print(\"Error: Sensor locations missing or incorrect dimensions (expected 102).\")\n        return\n\n    # Calculate magnitude per electrode location (sqrt(Ex^2 + Ey^2))\n    electrode_magnitudes = np.sqrt(weights[0::2]**2 + weights[1::2]**2)\n    if len(electrode_magnitudes) != 102:\n         print(f\"Error: Calculated magnitude array size is {len(electrode_magnitudes)}, expected 102.\")\n         return\n\n    # Create grid and interpolate\n    xi = np.linspace(sensor_x.min() - 0.5, sensor_x.max() + 0.5, grid_resolution)\n    yi = np.linspace(sensor_y.min() - 0.5, sensor_y.max() + 0.5, grid_resolution)\n    xi, yi = np.meshgrid(xi, yi)\n    zi = griddata((sensor_x, sensor_y), electrode_magnitudes, (xi, yi), method='cubic')\n\n    plt.figure(figsize=(7, 6))\n    contour = plt.contourf(xi, yi, zi, levels=15, cmap=plt.cm.viridis)\n    plt.colorbar(contour, label='SVM Weight Magnitude')\n    # Optionally plot sensor locations: plt.scatter(sensor_x, sensor_y, c='red', s=5)\n    plt.gca().set_aspect('equal', adjustable='box')\n    plt.axis('off') # Turn off axes per project description\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_overall_roc(true_labels, decision_scores, data_label=\"Data\", title=\"Overall Cross-Validated ROC Curve\"):\n    \"\"\"Plots the overall ROC curve from aggregated labels and scores.\"\"\"\n    if true_labels is None or decision_scores is None or len(true_labels) != len(decision_scores) or len(true_labels) == 0:\n        print(f\"Error: Missing or mismatched data for Overall ROC plot for {data_label}.\")\n        return\n\n    fpr, tpr, thresholds = roc_curve(true_labels, decision_scores)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Overall ROC ({data_label}, AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance (AUC = 0.50)')\n    plt.xlim([-0.02, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(title)\n    plt.legend(loc=\"lower right\")\n    plt.grid(True, linestyle=':')\n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_individual_and_overall_roc(outer_fold_true_labels, outer_fold_scores,\n                                    all_true_labels, all_decision_scores,\n                                    data_label=\"Data\", title=\"Individual Fold and Overall ROC Curves\"):\n    \"\"\"Plots individual fold ROCs and the overall aggregated ROC curve.\"\"\"\n    if not outer_fold_true_labels or not outer_fold_scores or len(outer_fold_true_labels) != len(outer_fold_scores):\n        print(f\"Error: Missing or mismatched per-fold data for Individual ROC plot for {data_label}.\")\n        return\n    if all_true_labels is None or all_decision_scores is None or len(all_true_labels) == 0:\n        print(f\"Error: Missing aggregated data for Overall ROC plot for {data_label}.\")\n        return\n\n    plt.figure(figsize=(9, 7))\n    n_folds = len(outer_fold_true_labels)\n\n    # Plot individual folds\n    for i in range(n_folds):\n        if len(outer_fold_true_labels[i]) &gt; 0 and len(outer_fold_scores[i]) &gt; 0:\n             fpr, tpr, _ = roc_curve(outer_fold_true_labels[i], outer_fold_scores[i])\n             fold_auc = auc(fpr, tpr)\n             plt.plot(fpr, tpr, lw=1, alpha=0.4, label=f'Fold {i+1} (AUC = {fold_auc:.2f})')\n        else:\n             print(f\"Warning: No data for Fold {i+1} in individual ROC plot.\")\n\n\n    # Plot overall curve\n    fpr_all, tpr_all, _ = roc_curve(all_true_labels, all_decision_scores)\n    roc_auc_all = auc(fpr_all, tpr_all)\n    plt.plot(fpr_all, tpr_all, color='b', lw=2.5, alpha=0.9, label=f'Overall ROC ({data_label}, AUC = {roc_auc_all:.2f})')\n\n    # Plot chance line\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance (AUC = 0.50)')\n\n    plt.xlim([-0.02, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(title)\n    plt.legend(loc=\"lower right\", fontsize='small')\n    plt.grid(True, linestyle=':')\n    plt.tight_layout()\n    plt.show()\n\n\n# === 4. Main Execution Block ===\n\nif __name__ == \"__main__\":\n    print(\"\\n=== Starting BCI Analysis ===\")\n\n    # --- Configuration ---\n    # Adjust these paths if your files are located elsewhere\n    OVERT_FILE_1 = '../assets/feaSubEOvert_1.csv'\n    OVERT_FILE_2 = '../assets/feaSubEOvert_2.csv'\n    IMG_FILE_1 = '../assets/feaSubEImg_1.csv'\n    IMG_FILE_2 = '../assets/feaSubEImg_2.csv'\n    SENSOR_FILE = '../assets/BCIsensor_xy.csv'\n\n    # --- Load Sensor Locations ---\n    sensor_x, sensor_y = load_sensor_locations(SENSOR_FILE)\n\n    # --- Analysis for Overt Movement Data ---\n    print(\"\\n\" + \"=\"*30)\n    print(\" Processing Overt Movement Data\")\n    print(\"=\"*30)\n    X_overt, y_overt = load_and_prepare_data(OVERT_FILE_1, OVERT_FILE_2)\n\n    if X_overt is not None:\n        overt_results = perform_two_level_cv(X_overt, y_overt, data_label=\"Overt\")\n\n        if overt_results:\n            print(\"\\n--- Generating Plots for Overt Data ---\")\n            # Plot Fold 1 SVM Weights (Stem)\n            plot_svm_weights_stem(overt_results['fold1_coefficients'],\n                                  title=\"Overt Data: SVM Channel Weights (Fold 1)\")\n\n            # Plot Fold 1 SVM Weight Magnitudes (Brain Surface)\n            plot_weights_on_brain(overt_results['fold1_coefficients'], sensor_x, sensor_y,\n                                  title=\"Overt Data: SVM Weight Magnitude on Brain Surface (Fold 1)\")\n\n            # Plot Overall ROC\n            plot_overall_roc(overt_results['all_true_labels'], overt_results['all_decision_scores'],\n                             data_label=\"Overt\", title=\"Overt Data: Overall Cross-Validated ROC Curve\")\n\n            # Plot Individual + Overall ROCs\n            plot_individual_and_overall_roc(overt_results['outer_fold_true_labels'], overt_results['outer_fold_scores'],\n                                            overt_results['all_true_labels'], overt_results['all_decision_scores'],\n                                            data_label=\"Overt\", title=\"Overt Data: Individual Fold and Overall ROC Curves\")\n    else:\n        print(\"Skipping Overt data analysis due to loading errors.\")\n\n\n    # --- Analysis for Imagined Movement Data ---\n    print(\"\\n\" + \"=\"*30)\n    print(\" Processing Imagined Movement Data\")\n    print(\"=\"*30)\n    X_img, y_img = load_and_prepare_data(IMG_FILE_1, IMG_FILE_2)\n\n    if X_img is not None:\n        img_results = perform_two_level_cv(X_img, y_img, data_label=\"Imagined\")\n\n        if img_results:\n            print(\"\\n--- Generating Plots for Imagined Data ---\")\n            # Plot Fold 1 SVM Weights (Stem)\n            plot_svm_weights_stem(img_results['fold1_coefficients'],\n                                  title=\"Imagined Data: SVM Channel Weights (Fold 1)\")\n\n            # Plot Fold 1 SVM Weight Magnitudes (Brain Surface)\n            plot_weights_on_brain(img_results['fold1_coefficients'], sensor_x, sensor_y,\n                                  title=\"Imagined Data: SVM Weight Magnitude on Brain Surface (Fold 1)\")\n\n            # Plot Overall ROC\n            plot_overall_roc(img_results['all_true_labels'], img_results['all_decision_scores'],\n                             data_label=\"Imagined\", title=\"Imagined Data: Overall Cross-Validated ROC Curve\")\n\n            # Plot Individual + Overall ROCs\n            plot_individual_and_overall_roc(img_results['outer_fold_true_labels'], img_results['outer_fold_scores'],\n                                            img_results['all_true_labels'], img_results['all_decision_scores'],\n                                            data_label=\"Imagined\", title=\"Imagined Data: Individual Fold and Overall ROC Curves\")\n    else:\n        print(\"Skipping Imagined data analysis due to loading errors.\")\n\n\n    # --- TODO: Add Cross-Training Scenarios if needed ---\n    # Example: Train on Overt, Test on Imagined\n    # 1. Train final model on ALL Overt data using the *average* or *mode* of optimal_Cs from overt_results\n    #    (or perform one final inner CV on all Overt data to find best C)\n    # 2. Scale Imagined data using scaler fit on Overt data\n    # 3. Predict/get decision scores on scaled Imagined data\n    # 4. Calculate ROC/accuracy\n\n    print(\"\\n=== BCI Analysis Script Finished ===\")\n\n--- BCI Movement Decoding Analysis Script ---\n\n=== Starting BCI Analysis ===\nLoading sensor locations from: ../assets/BCIsensor_xy.csv\nSensor locations loaded. Shape: (102, 2)\n\n==============================\n Processing Overt Movement Data\n==============================\nLoading data: ../assets/feaSubEOvert_1.csv (Label 0), ../assets/feaSubEOvert_2.csv (Label 1)\nData loaded successfully. X shape: (240, 204), y shape: (240,)\n\n--- Starting 6-Fold Outer CV for Overt Data ---\n  Outer Fold 1/6\n  Outer Fold 1 completed. Accuracy: 0.9500. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 2/6\n  Outer Fold 2 completed. Accuracy: 0.9750. Optimal C: 1. Time: 0.1s\n  Outer Fold 3/6\n  Outer Fold 3 completed. Accuracy: 0.9750. Optimal C: 1. Time: 0.1s\n  Outer Fold 4/6\n  Outer Fold 4 completed. Accuracy: 0.9000. Optimal C: 0.001. Time: 0.1s\n  Outer Fold 5/6\n  Outer Fold 5 completed. Accuracy: 0.9750. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 6/6\n  Outer Fold 6 completed. Accuracy: 0.9500. Optimal C: 0.1. Time: 0.0s\n\nFinished 6-fold CV for Overt data.\nTotal CV Time: 0.3s\nOptimal C found per fold: [0.1, 1, 1, 0.001, 0.1, 0.1]\nAccuracy per fold: ['0.9500', '0.9750', '0.9750', '0.9000', '0.9750', '0.9500']\nAverage Accuracy: 0.9542 +/- 0.0267\n\n--- Generating Plots for Overt Data ---\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n==============================\n Processing Imagined Movement Data\n==============================\nLoading data: ../assets/feaSubEImg_1.csv (Label 0), ../assets/feaSubEImg_2.csv (Label 1)\nData loaded successfully. X shape: (240, 204), y shape: (240,)\n\n--- Starting 6-Fold Outer CV for Imagined Data ---\n  Outer Fold 1/6\n  Outer Fold 1 completed. Accuracy: 0.8500. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 2/6\n  Outer Fold 2 completed. Accuracy: 0.9500. Optimal C: 0.01. Time: 0.1s\n  Outer Fold 3/6\n  Outer Fold 3 completed. Accuracy: 0.8000. Optimal C: 0.01. Time: 0.1s\n  Outer Fold 4/6\n  Outer Fold 4 completed. Accuracy: 0.9250. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 5/6\n  Outer Fold 5 completed. Accuracy: 0.8500. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 6/6\n  Outer Fold 6 completed. Accuracy: 0.9500. Optimal C: 0.1. Time: 0.1s\n\nFinished 6-fold CV for Imagined data.\nTotal CV Time: 0.5s\nOptimal C found per fold: [0.1, 0.01, 0.01, 0.1, 0.1, 0.1]\nAccuracy per fold: ['0.8500', '0.9500', '0.8000', '0.9250', '0.8500', '0.9500']\nAverage Accuracy: 0.8875 +/- 0.0573\n\n--- Generating Plots for Imagined Data ---\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n=== BCI Analysis Script Finished ===\n\n\n\n# bci_analysis_v2.py\n# Integrated script for BCI Movement Decoding Mini-Project #2 (ECE 580)\n# Added support for different kernels and cross-training scenarios.\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import griddata\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, roc_curve, auc, make_scorer\nimport time\nimport warnings\n\n# Suppress ConvergenceWarning from SVC with low iterations (can happen in inner loops)\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n\nprint(\"--- BCI Movement Decoding Analysis Script v2 ---\")\n\n# === 1. Data Loading Functions (Unchanged) ===\n\ndef load_and_prepare_data(file1, file2, label1=0, label2=1):\n    \"\"\"Loads feature data, labels, and concatenates.\"\"\"\n    print(f\"Loading data: {file1} (Label {label1}), {file2} (Label {label2})\")\n    try:\n        df1 = pd.read_csv(file1, header=None).T\n        df2 = pd.read_csv(file2, header=None).T\n        if df1.shape[1] != 204 or df2.shape[1] != 204:\n             print(f\"Warning: Expected 204 features. Got {df1.shape[1]} & {df2.shape[1]}.\")\n        y1 = np.full(df1.shape[0], label1)\n        y2 = np.full(df2.shape[0], label2)\n        X = pd.concat([df1, df2], ignore_index=True).values\n        y = np.concatenate([y1, y2])\n        print(f\"Data loaded. X shape: {X.shape}, y shape: {y.shape}\")\n        return X, y\n    except FileNotFoundError as e:\n        print(f\"Error: File not found - {e}.\")\n        return None, None\n    except Exception as e:\n        print(f\"Error loading data files: {e}\")\n        return None, None\n\ndef load_sensor_locations(filename=\"BCIsensor_xy.csv\"):\n    \"\"\"Loads sensor locations.\"\"\"\n    print(f\"Loading sensor locations from: {filename}\")\n    try:\n        locations = pd.read_csv(filename, header=None, names=['x', 'y']).values\n        if locations.shape[0] != 102 or locations.shape[1] != 2:\n            print(f\"Warning: Expected 102x2 shape, got {locations.shape}.\")\n        print(f\"Sensor locations loaded. Shape: {locations.shape}\")\n        return locations[:, 0], locations[:, 1]\n    except FileNotFoundError:\n        print(f\"Error: Sensor location file '{filename}' not found.\")\n        return None, None\n    except Exception as e:\n        print(f\"Error loading sensor locations: {e}\")\n        return None, None\n\n# === 2. Core Analysis Functions ===\n\ndef perform_two_level_cv(X, y, data_label=\"Data\", kernel='linear', gamma='scale', degree=3, outer_k=6, inner_k=5):\n    \"\"\"\n    Performs two-level stratified CV for SVM with specified kernel.\n    Tunes ONLY hyperparameter C based on inner CV accuracy.\n\n    Args:\n        X, y: Feature matrix and labels.\n        data_label (str): Label for the dataset type.\n        kernel (str): SVM kernel ('linear', 'rbf', 'poly', 'sigmoid').\n        gamma (float or 'scale'/'auto'): Kernel coefficient for 'rbf', 'poly', 'sigmoid'.\n        degree (int): Degree for 'poly' kernel.\n        outer_k (int): Number of outer folds.\n        inner_k (int): Number of inner folds.\n\n    Returns:\n        dict: Results dictionary or None on error.\n    \"\"\"\n    if X is None or y is None:\n        print(f\"Error: Missing input data for CV on {data_label}.\")\n        return None\n\n    C_range = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] # Fine-tune if needed\n\n    outer_cv = StratifiedKFold(n_splits=outer_k, shuffle=True, random_state=42)\n    inner_cv = StratifiedKFold(n_splits=inner_k, shuffle=True, random_state=42)\n\n    # Initialization\n    outer_fold_accuracies, optimal_Cs = [], []\n    all_true_labels, all_decision_scores = [], []\n    outer_fold_true_labels, outer_fold_scores = [], []\n    fold1_coefficients = None # Only stored for linear kernel\n\n    print(f\"\\n--- Starting {outer_k}-Fold Outer CV for {data_label} Data (Kernel: {kernel}) ---\")\n    start_time_cv = time.time()\n\n    # Outer loop\n    for i, (train_outer_idx, test_outer_idx) in enumerate(outer_cv.split(X, y)):\n        fold_start_time = time.time()\n        print(f\"  Outer Fold {i+1}/{outer_k}\")\n        X_train_outer, X_test_outer = X[train_outer_idx], X[test_outer_idx]\n        y_train_outer, y_test_outer = y[train_outer_idx], y[test_outer_idx]\n\n        scaler = StandardScaler()\n        X_train_outer_scaled = scaler.fit_transform(X_train_outer)\n        X_test_outer_scaled = scaler.transform(X_test_outer)\n\n        # Inner loop to find best C (only C is tuned here)\n        best_inner_acc = -1\n        best_C_for_fold = C_range[0]\n        for C_val in C_range:\n            inner_fold_accuracies = []\n            for j, (train_inner_idx, val_inner_idx) in enumerate(inner_cv.split(X_train_outer_scaled, y_train_outer)):\n                X_train_inner, X_val_inner = X_train_outer_scaled[train_inner_idx], X_train_outer_scaled[val_inner_idx]\n                y_train_inner, y_val_inner = y_train_outer[train_inner_idx], y_train_outer[val_inner_idx]\n                svm_inner = SVC(kernel=kernel, C=C_val, gamma=gamma, degree=degree,\n                                random_state=42, probability=False)\n                svm_inner.fit(X_train_inner, y_train_inner)\n                accuracy = svm_inner.score(X_val_inner, y_val_inner)\n                inner_fold_accuracies.append(accuracy)\n            avg_inner_acc = np.mean(inner_fold_accuracies)\n            if avg_inner_acc &gt; best_inner_acc:\n                best_inner_acc = avg_inner_acc\n                best_C_for_fold = C_val\n\n        optimal_Cs.append(best_C_for_fold)\n\n        # Train final SVM for outer fold\n        final_svm = SVC(kernel=kernel, C=best_C_for_fold, gamma=gamma, degree=degree,\n                        random_state=42, probability=False)\n        final_svm.fit(X_train_outer_scaled, y_train_outer)\n\n        # Evaluate and store results\n        outer_accuracy = final_svm.score(X_test_outer_scaled, y_test_outer)\n        outer_fold_accuracies.append(outer_accuracy)\n        decision_scores = final_svm.decision_function(X_test_outer_scaled)\n        all_true_labels.extend(y_test_outer)\n        all_decision_scores.extend(decision_scores)\n        outer_fold_true_labels.append(y_test_outer)\n        outer_fold_scores.append(decision_scores)\n\n        # Store Fold 1 coefficients ONLY for linear kernel\n        if i == 0 and kernel == 'linear':\n            fold1_coefficients = final_svm.coef_.flatten()\n        elif i == 0 and kernel != 'linear':\n             print(\"    Note: Coefficients (.coef_) not available for non-linear kernels. Skipping weight plots.\")\n\n\n        fold_end_time = time.time()\n        print(f\"  Outer Fold {i+1} completed. Accuracy: {outer_accuracy:.4f}. Optimal C: {best_C_for_fold}. Time: {fold_end_time - fold_start_time:.1f}s\")\n\n    # --- End Outer Loop ---\n    end_time_cv = time.time()\n    average_accuracy = np.mean(outer_fold_accuracies)\n    std_dev_accuracy = np.std(outer_fold_accuracies)\n\n    print(f\"\\nFinished {outer_k}-fold CV for {data_label} data (Kernel: {kernel}).\")\n    print(f\"Total CV Time: {end_time_cv - start_time_cv:.1f}s\")\n    print(f\"Optimal C found per fold: {optimal_Cs}\")\n    print(f\"Accuracy per fold: {[f'{acc:.4f}' for acc in outer_fold_accuracies]}\")\n    print(f\"Average Accuracy: {average_accuracy:.4f} +/- {std_dev_accuracy:.4f}\")\n\n    results = {\n        'avg_accuracy': average_accuracy, 'std_accuracy': std_dev_accuracy,\n        'optimal_Cs': optimal_Cs, 'fold_accuracies': outer_fold_accuracies,\n        'all_true_labels': np.array(all_true_labels),\n        'all_decision_scores': np.array(all_decision_scores),\n        'fold1_coefficients': fold1_coefficients,\n        'outer_fold_true_labels': outer_fold_true_labels,\n        'outer_fold_scores': outer_fold_scores,\n        'kernel': kernel # Store kernel used\n    }\n    return results\n\n\ndef tune_hyperparameters(X_train, y_train, kernel, C_range, gamma_range=None, degree_range=None, n_splits=5):\n    \"\"\"\n    Tunes SVM hyperparameters (C and optionally gamma/degree) using GridSearchCV.\n    Scales data internally within CV.\n\n    Args:\n        X_train, y_train: Training data.\n        kernel (str): SVM kernel type.\n        C_range (list): List of C values to test.\n        gamma_range (list, optional): List of gamma values.\n        degree_range (list, optional): List of degree values.\n        n_splits (int): Number of CV folds for tuning.\n\n    Returns:\n        dict: Best parameters found by GridSearchCV.\n    \"\"\"\n    print(f\"    Tuning hyperparameters (Kernel: {kernel}) using {n_splits}-fold CV...\")\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train) # Scale data once before tuning\n\n    param_grid = {'C': C_range}\n    if kernel in ['rbf', 'poly', 'sigmoid'] and gamma_range:\n        param_grid['gamma'] = gamma_range\n    if kernel == 'poly' and degree_range:\n        param_grid['degree'] = degree_range\n\n    # Use accuracy for scoring, matching the 2-level CV inner loop\n    scorer = make_scorer(accuracy_score)\n    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    # Note: For large datasets/parameter grids, GridSearchCV can be slow.\n    # Consider RandomizedSearchCV for efficiency if needed.\n    grid_search = GridSearchCV(SVC(kernel=kernel, random_state=42, probability=False),\n                               param_grid, scoring=scorer, cv=cv, n_jobs=-1) # Use all available CPU cores\n    grid_search.fit(X_train_scaled, y_train)\n\n    print(f\"    Best parameters found: {grid_search.best_params_} (Best Score: {grid_search.best_score_:.4f})\")\n    return grid_search.best_params_\n\n\ndef perform_cross_training(X_train, y_train, X_test, y_test, train_label, test_label, kernel='linear', gamma='scale', degree=3):\n    \"\"\"\n    Performs cross-training: Tunes hyperparameters on training set,\n    trains final model, tests on the test set.\n\n    Args:\n        X_train, y_train: Training features and labels.\n        X_test, y_test: Testing features and labels.\n        train_label (str): Label for training data type.\n        test_label (str): Label for testing data type.\n        kernel (str): SVM kernel type.\n        gamma, degree: Kernel parameters.\n\n    Returns:\n        dict: Results including accuracy, true labels, scores or None on error.\n    \"\"\"\n    if X_train is None or y_train is None or X_test is None or y_test is None:\n        print(\"Error: Missing input data for cross-training.\")\n        return None\n\n    print(f\"\\n--- Cross-Training: Train on {train_label}, Test on {test_label} (Kernel: {kernel}) ---\")\n    start_time_xt = time.time()\n\n    # 1. Tune Hyperparameters on the *entire* Training Set\n    # Define ranges - adjust as needed, especially for gamma/degree if tuning them\n    C_range_xt = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n    gamma_range_xt = ['scale', 'auto'] # Example if tuning gamma\n    # degree_range_xt = [2, 3, 4]     # Example if tuning degree\n\n    # Only tune C for now for simplicity, matching the 2-level CV approach\n    # To tune gamma/degree, pass gamma_range_xt/degree_range_xt to tune_hyperparameters\n    best_params = tune_hyperparameters(X_train, y_train, kernel, C_range_xt)\n                                        # gamma_range=gamma_range_xt if kernel != 'linear' else None,\n                                        # degree_range=degree_range_xt if kernel == 'poly' else None)\n\n    # Extract best parameters, providing defaults if not tuned/found\n    best_C = best_params.get('C', 1.0) # Default C=1.0 if tuning fails? Risky, maybe error out.\n    best_gamma = best_params.get('gamma', gamma) # Use passed gamma if not tuned\n    best_degree = best_params.get('degree', degree) # Use passed degree if not tuned\n\n    # 2. Train Final Model on Scaled Training Data\n    print(\"    Training final model on entire training set...\")\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    final_svm = SVC(kernel=kernel, C=best_C, gamma=best_gamma, degree=best_degree,\n                    random_state=42, probability=False)\n    final_svm.fit(X_train_scaled, y_train)\n\n    # 3. Test on Scaled Testing Data\n    print(\"    Testing model on test set...\")\n    X_test_scaled = scaler.transform(X_test) # Use scaler fit on training data\n    accuracy = final_svm.score(X_test_scaled, y_test)\n    decision_scores = final_svm.decision_function(X_test_scaled)\n\n    end_time_xt = time.time()\n    print(f\"Cross-Training completed. Time: {end_time_xt - start_time_xt:.1f}s\")\n    print(f\"Test Accuracy: {accuracy:.4f}\")\n\n    results = {\n        'accuracy': accuracy,\n        'true_labels': y_test,\n        'decision_scores': decision_scores,\n        'best_params': best_params,\n        'kernel': kernel\n    }\n    return results\n\n\n# === 3. Plotting Functions (Mostly Unchanged) ===\n\ndef plot_svm_weights_stem(weights, title=\"SVM Channel Weights (Fold 1)\", top_n=6):\n    \"\"\"Generates a stem plot of SVM weights, highlighting top N.\"\"\"\n    if weights is None: # Check moved from original position\n        print(f\"Info: Skipping stem plot '{title}' (weights not available, likely non-linear kernel).\")\n        return\n    if len(weights) == 0:\n        print(\"Error: Empty weights provided for stem plot.\")\n        return\n\n    n_channels = len(weights)\n    channel_indices = np.arange(1, n_channels + 1)\n    dominant_indices = np.argsort(np.abs(weights))[-top_n:]\n\n    plt.figure(figsize=(12, 6))\n    markerline, stemlines, baseline = plt.stem(channel_indices, weights, linefmt='grey', markerfmt='o', basefmt='r-', label='_nolegend_')\n    plt.setp(markerline, markersize=4, markerfacecolor='grey', markeredgecolor='black')\n    for idx in dominant_indices:\n        plt.stem(channel_indices[idx], weights[idx], linefmt='b-', markerfmt='bo', basefmt=' ')\n        plt.text(channel_indices[idx], weights[idx] + 0.05 * np.sign(weights[idx]), f'{weights[idx]:.2f}',\n                 ha='center', va='bottom', color='blue', fontsize=9)\n    dominant_proxy = plt.Line2D([0], [0], linestyle='none', c='b', marker='o', markersize=5, label=f'Top {top_n} Dominant Channels')\n    plt.xlabel(\"Channel Index\"); plt.ylabel(\"SVM Weight\"); plt.title(title)\n    plt.xlim(0, n_channels + 1); plt.legend(handles=[dominant_proxy])\n    plt.grid(True, axis='y', linestyle=':'); plt.tight_layout(); plt.show()\n\n\ndef plot_weights_on_brain(weights, sensor_x, sensor_y, title=\"SVM Weight Magnitude on Brain Surface (Fold 1)\", grid_resolution=100):\n    \"\"\"Visualizes SVM weight magnitude interpolated on the brain surface.\"\"\"\n    if weights is None: # Check moved from original position\n        print(f\"Info: Skipping brain plot '{title}' (weights not available, likely non-linear kernel).\")\n        return\n    if len(weights) != 204:\n        print(\"Error: Expected 204 weights for brain plot.\")\n        return\n    if sensor_x is None or sensor_y is None or len(sensor_x) != 102 or len(sensor_y) != 102:\n        print(\"Error: Sensor locations missing or incorrect for brain plot.\")\n        return\n\n    electrode_magnitudes = np.sqrt(weights[0::2]**2 + weights[1::2]**2)\n    if len(electrode_magnitudes) != 102:\n         print(f\"Error: Calculated magnitude array size incorrect ({len(electrode_magnitudes)}).\"); return\n\n    xi = np.linspace(sensor_x.min()-0.5, sensor_x.max()+0.5, grid_resolution)\n    yi = np.linspace(sensor_y.min()-0.5, sensor_y.max()+0.5, grid_resolution)\n    xi, yi = np.meshgrid(xi, yi)\n    zi = griddata((sensor_x, sensor_y), electrode_magnitudes, (xi, yi), method='cubic')\n\n    plt.figure(figsize=(7, 6))\n    contour = plt.contourf(xi, yi, zi, levels=15, cmap=plt.cm.viridis)\n    plt.colorbar(contour, label='SVM Weight Magnitude')\n    plt.gca().set_aspect('equal', adjustable='box'); plt.axis('off'); plt.title(title)\n    plt.tight_layout(); plt.show()\n\n\ndef plot_overall_roc(true_labels, decision_scores, data_label=\"Data\", title=\"Overall ROC Curve\"):\n    \"\"\"Plots the overall ROC curve from aggregated/single run labels and scores.\"\"\"\n    if true_labels is None or decision_scores is None or len(true_labels) != len(decision_scores) or len(true_labels) == 0:\n        print(f\"Error: Missing/mismatched data for ROC plot '{title}'.\")\n        return\n\n    fpr, tpr, thresholds = roc_curve(true_labels, decision_scores)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC ({data_label}, AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance (AUC = 0.50)')\n    plt.xlim([-0.02, 1.0]); plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title(title)\n    plt.legend(loc=\"lower right\"); plt.grid(True, linestyle=':'); plt.tight_layout(); plt.show()\n\n\ndef plot_individual_and_overall_roc(outer_fold_true_labels, outer_fold_scores,\n                                    all_true_labels, all_decision_scores,\n                                    data_label=\"Data\", title=\"Individual Fold and Overall ROC Curves\"):\n    \"\"\"Plots individual fold ROCs and the overall aggregated ROC curve.\"\"\"\n    if not outer_fold_true_labels or not outer_fold_scores or len(outer_fold_true_labels) != len(outer_fold_scores):\n        print(f\"Error: Missing/mismatched per-fold data for Indiv. ROC plot '{title}'.\")\n        return\n    if all_true_labels is None or all_decision_scores is None or len(all_true_labels) == 0:\n        print(f\"Error: Missing aggregated data for Indiv. ROC plot '{title}'.\")\n        return\n\n    plt.figure(figsize=(9, 7))\n    n_folds = len(outer_fold_true_labels)\n    for i in range(n_folds):\n        if len(outer_fold_true_labels[i]) &gt; 0 and len(outer_fold_scores[i]) &gt; 0:\n             fpr, tpr, _ = roc_curve(outer_fold_true_labels[i], outer_fold_scores[i])\n             fold_auc = auc(fpr, tpr)\n             plt.plot(fpr, tpr, lw=1, alpha=0.4, label=f'Fold {i+1} (AUC = {fold_auc:.2f})')\n    fpr_all, tpr_all, _ = roc_curve(all_true_labels, all_decision_scores)\n    roc_auc_all = auc(fpr_all, tpr_all)\n    plt.plot(fpr_all, tpr_all, color='b', lw=2.5, alpha=0.9, label=f'Overall ROC ({data_label}, AUC = {roc_auc_all:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance (AUC = 0.50)')\n    plt.xlim([-0.02, 1.0]); plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title(title)\n    plt.legend(loc=\"lower right\", fontsize='small'); plt.grid(True, linestyle=':')\n    plt.tight_layout(); plt.show()\n\n\n# === 4. Main Execution Block ===\n\nif __name__ == \"__main__\":\n    print(\"\\n=== Starting BCI Analysis v2 ===\")\n\n    # --- Configuration ---\n    OVERT_FILE_1 = '../assets/feaSubEOvert_1.csv'; OVERT_FILE_2 = '../assets/feaSubEOvert_2.csv'\n    IMG_FILE_1 = '../assets/feaSubEImg_1.csv'; IMG_FILE_2 = '../assets/feaSubEImg_2.csv'\n    SENSOR_FILE = '../assets/BCIsensor_xy.csv'\n    RUN_SAME_TRAIN = True  # Set to False to skip Overt-Overt, Img-Img\n    RUN_CROSS_TRAIN = True # Set to False to skip Overt-Img, Img-Overt\n    RUN_RBF_KERNEL_EXAMPLE = True # Set to False to skip RBF example\n\n    # --- Load Sensor Locations ---\n    sensor_x, sensor_y = load_sensor_locations(SENSOR_FILE)\n\n    # --- Load All Data ---\n    X_overt, y_overt = load_and_prepare_data(OVERT_FILE_1, OVERT_FILE_2)\n    X_img, y_img = load_and_prepare_data(IMG_FILE_1, IMG_FILE_2)\n\n    # --- Scenario 1 & 2: Same-Train (Linear Kernel) ---\n    if RUN_SAME_TRAIN:\n        # Overt Data (Linear)\n        print(\"\\n\" + \"=\"*30 + \"\\n Scenario: Same-Train Overt (Linear Kernel)\\n\" + \"=\"*30)\n        if X_overt is not None:\n            overt_results_lin = perform_two_level_cv(X_overt, y_overt, data_label=\"Overt\", kernel='linear')\n            if overt_results_lin:\n                plot_svm_weights_stem(overt_results_lin['fold1_coefficients'], title=\"Overt (Linear): SVM Weights (Fold 1)\")\n                plot_weights_on_brain(overt_results_lin['fold1_coefficients'], sensor_x, sensor_y, title=\"Overt (Linear): Weight Magnitude (Fold 1)\")\n                plot_individual_and_overall_roc(overt_results_lin['outer_fold_true_labels'], overt_results_lin['outer_fold_scores'],\n                                                overt_results_lin['all_true_labels'], overt_results_lin['all_decision_scores'],\n                                                data_label=\"Overt (Linear)\", title=\"Overt (Linear): Individual & Overall ROC\")\n\n        # Imagined Data (Linear)\n        print(\"\\n\" + \"=\"*30 + \"\\n Scenario: Same-Train Imagined (Linear Kernel)\\n\" + \"=\"*30)\n        if X_img is not None:\n             img_results_lin = perform_two_level_cv(X_img, y_img, data_label=\"Imagined\", kernel='linear')\n             if img_results_lin:\n                plot_svm_weights_stem(img_results_lin['fold1_coefficients'], title=\"Imagined (Linear): SVM Weights (Fold 1)\")\n                plot_weights_on_brain(img_results_lin['fold1_coefficients'], sensor_x, sensor_y, title=\"Imagined (Linear): Weight Magnitude (Fold 1)\")\n                plot_individual_and_overall_roc(img_results_lin['outer_fold_true_labels'], img_results_lin['outer_fold_scores'],\n                                                img_results_lin['all_true_labels'], img_results_lin['all_decision_scores'],\n                                                data_label=\"Imagined (Linear)\", title=\"Imagined (Linear): Individual & Overall ROC\")\n\n    # --- Scenario 3 & 4: Cross-Train (Linear Kernel) ---\n    if RUN_CROSS_TRAIN:\n        # Train Overt -&gt; Test Imagined (Linear)\n        print(\"\\n\" + \"=\"*30 + \"\\n Scenario: Cross-Train Overt -&gt; Imagined (Linear Kernel)\\n\" + \"=\"*30)\n        if X_overt is not None and X_img is not None:\n            xt_ov_img_lin = perform_cross_training(X_overt, y_overt, X_img, y_img, \"Overt\", \"Imagined\", kernel='linear')\n            if xt_ov_img_lin:\n                 plot_overall_roc(xt_ov_img_lin['true_labels'], xt_ov_img_lin['decision_scores'],\n                                  data_label=\"Train Overt, Test Imagined (Linear)\",\n                                  title=\"Cross-Train ROC: Overt -&gt; Imagined (Linear)\")\n\n        # Train Imagined -&gt; Test Overt (Linear)\n        print(\"\\n\" + \"=\"*30 + \"\\n Scenario: Cross-Train Imagined -&gt; Overt (Linear Kernel)\\n\" + \"=\"*30)\n        if X_overt is not None and X_img is not None:\n             xt_img_ov_lin = perform_cross_training(X_img, y_img, X_overt, y_overt, \"Imagined\", \"Overt\", kernel='linear')\n             if xt_img_ov_lin:\n                 plot_overall_roc(xt_img_ov_lin['true_labels'], xt_img_ov_lin['decision_scores'],\n                                  data_label=\"Train Imagined, Test Overt (Linear)\",\n                                  title=\"Cross-Train ROC: Imagined -&gt; Overt (Linear)\")\n\n    # --- Example: Same-Train with RBF Kernel ---\n    if RUN_RBF_KERNEL_EXAMPLE:\n        print(\"\\n\" + \"=\"*30 + \"\\n Scenario: Same-Train Overt (RBF Kernel Example)\\n\" + \"=\"*30)\n        if X_overt is not None:\n            # Note: Using default gamma='scale', only tuning C\n            overt_results_rbf = perform_two_level_cv(X_overt, y_overt, data_label=\"Overt\", kernel='rbf', gamma='scale')\n            if overt_results_rbf:\n                # Stem and Brain plots will be skipped automatically as kernel is not 'linear'\n                plot_svm_weights_stem(overt_results_rbf['fold1_coefficients'], title=\"Overt (RBF): SVM Weights (Fold 1)\")\n                plot_weights_on_brain(overt_results_rbf['fold1_coefficients'], sensor_x, sensor_y, title=\"Overt (RBF): Weight Magnitude (Fold 1)\")\n                plot_individual_and_overall_roc(overt_results_rbf['outer_fold_true_labels'], overt_results_rbf['outer_fold_scores'],\n                                                overt_results_rbf['all_true_labels'], overt_results_rbf['all_decision_scores'],\n                                                data_label=\"Overt (RBF)\", title=\"Overt (RBF): Individual & Overall ROC\")\n\n\n    print(\"\\n=== BCI Analysis Script v2 Finished ===\")\n\n--- BCI Movement Decoding Analysis Script v2 ---\n\n=== Starting BCI Analysis v2 ===\nLoading sensor locations from: ../assets/BCIsensor_xy.csv\nSensor locations loaded. Shape: (102, 2)\nLoading data: ../assets/feaSubEOvert_1.csv (Label 0), ../assets/feaSubEOvert_2.csv (Label 1)\nData loaded. X shape: (240, 204), y shape: (240,)\nLoading data: ../assets/feaSubEImg_1.csv (Label 0), ../assets/feaSubEImg_2.csv (Label 1)\nData loaded. X shape: (240, 204), y shape: (240,)\n\n==============================\n Scenario: Same-Train Overt (Linear Kernel)\n==============================\n\n--- Starting 6-Fold Outer CV for Overt Data (Kernel: linear) ---\n  Outer Fold 1/6\n  Outer Fold 1 completed. Accuracy: 0.9500. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 2/6\n  Outer Fold 2 completed. Accuracy: 0.9750. Optimal C: 1. Time: 0.1s\n  Outer Fold 3/6\n  Outer Fold 3 completed. Accuracy: 0.9750. Optimal C: 1. Time: 0.1s\n  Outer Fold 4/6\n  Outer Fold 4 completed. Accuracy: 0.9000. Optimal C: 0.001. Time: 0.1s\n  Outer Fold 5/6\n  Outer Fold 5 completed. Accuracy: 0.9750. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 6/6\n  Outer Fold 6 completed. Accuracy: 0.9500. Optimal C: 0.1. Time: 0.0s\n\nFinished 6-fold CV for Overt data (Kernel: linear).\nTotal CV Time: 0.3s\nOptimal C found per fold: [0.1, 1, 1, 0.001, 0.1, 0.1]\nAccuracy per fold: ['0.9500', '0.9750', '0.9750', '0.9000', '0.9750', '0.9500']\nAverage Accuracy: 0.9542 +/- 0.0267\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n==============================\n Scenario: Same-Train Imagined (Linear Kernel)\n==============================\n\n--- Starting 6-Fold Outer CV for Imagined Data (Kernel: linear) ---\n  Outer Fold 1/6\n  Outer Fold 1 completed. Accuracy: 0.8500. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 2/6\n  Outer Fold 2 completed. Accuracy: 0.9500. Optimal C: 0.01. Time: 0.1s\n  Outer Fold 3/6\n  Outer Fold 3 completed. Accuracy: 0.8000. Optimal C: 0.01. Time: 0.1s\n  Outer Fold 4/6\n  Outer Fold 4 completed. Accuracy: 0.9250. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 5/6\n  Outer Fold 5 completed. Accuracy: 0.8500. Optimal C: 0.1. Time: 0.1s\n  Outer Fold 6/6\n  Outer Fold 6 completed. Accuracy: 0.9500. Optimal C: 0.1. Time: 0.1s\n\nFinished 6-fold CV for Imagined data (Kernel: linear).\nTotal CV Time: 0.5s\nOptimal C found per fold: [0.1, 0.01, 0.01, 0.1, 0.1, 0.1]\nAccuracy per fold: ['0.8500', '0.9500', '0.8000', '0.9250', '0.8500', '0.9500']\nAverage Accuracy: 0.8875 +/- 0.0573\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n==============================\n Scenario: Cross-Train Overt -&gt; Imagined (Linear Kernel)\n==============================\n\n--- Cross-Training: Train on Overt, Test on Imagined (Kernel: linear) ---\n    Tuning hyperparameters (Kernel: linear) using 5-fold CV...\n    Best parameters found: {'C': 0.1} (Best Score: 0.9583)\n    Training final model on entire training set...\n    Testing model on test set...\nCross-Training completed. Time: 1.3s\nTest Accuracy: 0.8917\n\n\n\n\n\n\n\n\n\n\n==============================\n Scenario: Cross-Train Imagined -&gt; Overt (Linear Kernel)\n==============================\n\n--- Cross-Training: Train on Imagined, Test on Overt (Kernel: linear) ---\n    Tuning hyperparameters (Kernel: linear) using 5-fold CV...\n    Best parameters found: {'C': 1} (Best Score: 0.9042)\n    Training final model on entire training set...\n    Testing model on test set...\nCross-Training completed. Time: 0.2s\nTest Accuracy: 0.9125\n\n\n\n\n\n\n\n\n\n\n==============================\n Scenario: Same-Train Overt (RBF Kernel Example)\n==============================\n\n--- Starting 6-Fold Outer CV for Overt Data (Kernel: rbf) ---\n  Outer Fold 1/6\n    Note: Coefficients (.coef_) not available for non-linear kernels. Skipping weight plots.\n  Outer Fold 1 completed. Accuracy: 0.9750. Optimal C: 1. Time: 0.1s\n  Outer Fold 2/6\n  Outer Fold 2 completed. Accuracy: 0.9250. Optimal C: 10. Time: 0.1s\n  Outer Fold 3/6\n  Outer Fold 3 completed. Accuracy: 0.9250. Optimal C: 10. Time: 0.1s\n  Outer Fold 4/6\n  Outer Fold 4 completed. Accuracy: 0.9250. Optimal C: 10. Time: 0.1s\n  Outer Fold 5/6\n  Outer Fold 5 completed. Accuracy: 0.9750. Optimal C: 10. Time: 0.1s\n  Outer Fold 6/6\n  Outer Fold 6 completed. Accuracy: 0.8750. Optimal C: 10. Time: 0.1s\n\nFinished 6-fold CV for Overt data (Kernel: rbf).\nTotal CV Time: 0.7s\nOptimal C found per fold: [1, 10, 10, 10, 10, 10]\nAccuracy per fold: ['0.9750', '0.9250', '0.9250', '0.9250', '0.9750', '0.8750']\nAverage Accuracy: 0.9333 +/- 0.0344\nInfo: Skipping stem plot 'Overt (RBF): SVM Weights (Fold 1)' (weights not available, likely non-linear kernel).\nInfo: Skipping brain plot 'Overt (RBF): Weight Magnitude (Fold 1)' (weights not available, likely non-linear kernel).\n\n\n\n\n\n\n\n\n\n\n=== BCI Analysis Script v2 Finished ==="
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brain-Computer Interface Movement Decoding",
    "section": "",
    "text": "Brain-computer interfaces (BCIs) have been explored for several decades as a potential pathway for individuals with paralysis or other disabilities to regain interaction with the world (cite: Brain Computer Interfaces, a review). However, significant challenges remain, spanning from effectively collecting brain signal data to accurately processing that data to understand user intent.\n\nProject Goals: This project introduces an approach for tackling one key aspect of this challenge: classifying electrical data recorded from the brain via electroencephalography (EEG) to decode a person’s intended movement. Specifically, we employ a machine learning model known as a Support Vector Machine (SVM) for this classification task.\nApproach Overview: The ultimate goal is to determine whether a person intends to move their left or right hand based solely on their brain activity, even without overt physical movement. The system enabling this is the BCI, which in this project comprises two main components: the EEG system for acquiring the raw neural signals, and the SVM algorithm for interpreting these signals and making the classification decision.\nReport Scope: By the conclusion of this report, we’ll provide a robust understanding of the SVM’s performance when applied to EEG data for movement intention decoding. This includes evaluating overall classification accuracy and analyzing specific factors within the model and data that influence this performance.\n\n\n\nAdvancements in BCIs could have a major impact on a large population of people. According to the 2013 US Paralysis Prevalence & Health Disparities Survey, nearly 5.4 million people live with paralysis (cite: prevelance and causes of paralysis). At that time, this represented almost 1.7% of all US citizens, and the number has likely grown since. Furthermore, paralysis often correlates with significant challenges in daily life and overall well-being; the survey noted that only 15.5% of these individuals were employed, and over 30% were smokers. Given the severe effects of paralysis, technologies that offer relief and restore function are crucial for improving quality of life. BCIs are one of the most promising avenues to restore movement capabilities improve quality of life for affected individuals (Brain-Computer interfaces, a reivew).\n\n\n\n\n\nOur brain is constantly producing signals electrical signals that tell our body what to do. However, this process is complex and reliant on many components in our body, any one of which can break down. In people where this has occurred, a Brain-Computer Interface (BCI) can behave as a supplementary way for the brain’s signals to reach and control the body. At its core, a BCI acts as a communication bridge, translating brain activity into commands for an external device, which bypasses the body’s normal neuromuscular pathways (BCI: a review cite). In order for the BCI to do this, we need to be able to both read and interpret the signals of our brain in meaningful ways. In this project, we focus on non-invasive BCIs that use Electroencephalography (EEG) to measure these signals.\nEEG employs sensors placed directly on the scalp to detect the brain’s electrical potentials. Although this is non-invasive and easier than many other methods, the signals acquired present their own challenges. The electrical signals are complex, often mixed with noise (from muscle movements, eye blinks, or external interference), and significantly attenuated by the skull and scalp tissues. Furthermore, using multiple electrodes simultaneously to capture sufficient spatial information results in very high-dimensional datasets, meaning each data point has many components to be considered. Effectively deciphering intended commands (like “move left” vs. “move right”) from this noisy, high-dimensional data requires sophisticated analysis techniques, which is where machine learning becomes essential.\n\n\n\nSupport Vector Machines (SVMs) are supervised machine learning models designed primarily for classification tasks, meaning they learn to assign data points to predefined categories. Given a new data point, an SVM determines which category it most likely belongs to based on patterns learned from labeled training data - meaning we feed it some starting data that’s already assigned to categories, and it learns from that. In the context of this project, our categories are simply “intended left movement” and “intended right movement.” The SVM’s job is to analyze the features extracted from an EEG signal segment and classify it as belonging to either the “left” or “right” intention category.\nConceptually, an SVM works by trying to find the “best” boundary that separates the data points of different classes in the feature space. Imagine it like this: you’ve got a few 2-D data points, and you plot them along the xy plane. Each data point is either red or green. Assume for now that all the red points are clustered in the top right, and all the green points in bottom left. An SVM would draw a boundary separating these data points.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import svm\n\n# Generate some sample data\nnp.random.seed(0)\n# Red points in Quadrant 1\nX_red = np.random.randn(10, 2) * 0.4 + [2, 2]\n# Green points in Quadrant 3\nX_green = np.random.randn(10, 2) * 0.4 + [-2, -2]\n\nX = np.vstack((X_red, X_green))\ny = np.array([0]*10 + [1]*10)  # 0: red, 1: green\n\n# Fit the SVM model\nclf = svm.SVC(kernel='linear')\nclf.fit(X, y)\n\n# Create a mesh to plot the decision boundary\nxx, yy = np.meshgrid(np.linspace(-4, 4, 500), np.linspace(-4, 4, 500))\nZ = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n# Plot 1: just the points\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\nplt.scatter(X_red[:, 0], X_red[:, 1], c='red', label='Class 0 (Red)')\nplt.scatter(X_green[:, 0], X_green[:, 1], c='green', label='Class 1 (Green)')\nplt.title('Red and Green Points')\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.legend()\nplt.grid(True)\n\n# Plot 2: with decision boundary\nplt.subplot(1, 2, 2)\nplt.scatter(X_red[:, 0], X_red[:, 1], c='red')\nplt.scatter(X_green[:, 0], X_green[:, 1], c='green')\nplt.contour(xx, yy, Z, levels=[0], colors='blue', linewidths=2)\nplt.title('SVM Decision Boundary')\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIn two dimensions (like above), this is a simple line. In higher dimensions (like our 204-dimensional EEG data), this boundary is a plane or a hyperplane. What makes SVMs distinct is their strategy for finding this boundary: they aim to maximize the margin, which is the distance between the separating hyperplane and the closest data points from each class. These closest points are called “support vectors” because they essentially support or define the position of the margin and the hyperplane. This principle of maximizing the margin often leads to classifiers that generalize well to new, unseen data. While the underlying mathematics involves optimization, the core idea is finding this maximal-margin separator.\nSVMs are especially well-suited for the EEG data in this project. EEG data is inherently high-dimensional (given the number of electrodes), and SVMs are effective in such high-dimensional spaces, potentially mitigating the “curse of dimensionality” better than some other algorithms. They can perform well even when the number of training samples is close to the number of features (which is relevant for our project), because of the emphasis on maximizing the margin. This emphasis can also help to reduce the impact of noise on our classifier.\nSVMs have applications beyond BCI and neuroscience. They’ve been used to classify text in various ways (such as detecting spam emails) (cite: support vector machine active learning), detect faces (cite: face recognition) and even predict geological events (cite: seismic events). As we can see, this technology is widely applicable, and its continued study has many potential benefits."
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "Brain-Computer Interface Movement Decoding",
    "section": "",
    "text": "Advancements in BCIs could have a major impact on a large population of people. According to the 2013 US Paralysis Prevalence & Health Disparities Survey, nearly 5.4 million people live with paralysis (cite: prevelance and causes of paralysis). At that time, this represented almost 1.7% of all US citizens, and the number has likely grown since. Furthermore, paralysis often correlates with significant challenges in daily life and overall well-being; the survey noted that only 15.5% of these individuals were employed, and over 30% were smokers. Given the severe effects of paralysis, technologies that offer relief and restore function are crucial for improving quality of life. BCIs are one of the most promising avenues to restore movement capabilities improve quality of life for affected individuals (Brain-Computer interfaces, a reivew)."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Brain-Computer Interface Movement Decoding",
    "section": "",
    "text": "Our brain is constantly producing signals electrical signals that tell our body what to do. However, this process is complex and reliant on many components in our body, any one of which can break down. In people where this has occurred, a Brain-Computer Interface (BCI) can behave as a supplementary way for the brain’s signals to reach and control the body. At its core, a BCI acts as a communication bridge, translating brain activity into commands for an external device, which bypasses the body’s normal neuromuscular pathways (BCI: a review cite). In order for the BCI to do this, we need to be able to both read and interpret the signals of our brain in meaningful ways. In this project, we focus on non-invasive BCIs that use Electroencephalography (EEG) to measure these signals.\nEEG employs sensors placed directly on the scalp to detect the brain’s electrical potentials. Although this is non-invasive and easier than many other methods, the signals acquired present their own challenges. The electrical signals are complex, often mixed with noise (from muscle movements, eye blinks, or external interference), and significantly attenuated by the skull and scalp tissues. Furthermore, using multiple electrodes simultaneously to capture sufficient spatial information results in very high-dimensional datasets, meaning each data point has many components to be considered. Effectively deciphering intended commands (like “move left” vs. “move right”) from this noisy, high-dimensional data requires sophisticated analysis techniques, which is where machine learning becomes essential.\n\n\n\nSupport Vector Machines (SVMs) are supervised machine learning models designed primarily for classification tasks, meaning they learn to assign data points to predefined categories. Given a new data point, an SVM determines which category it most likely belongs to based on patterns learned from labeled training data - meaning we feed it some starting data that’s already assigned to categories, and it learns from that. In the context of this project, our categories are simply “intended left movement” and “intended right movement.” The SVM’s job is to analyze the features extracted from an EEG signal segment and classify it as belonging to either the “left” or “right” intention category.\nConceptually, an SVM works by trying to find the “best” boundary that separates the data points of different classes in the feature space. Imagine it like this: you’ve got a few 2-D data points, and you plot them along the xy plane. Each data point is either red or green. Assume for now that all the red points are clustered in the top right, and all the green points in bottom left. An SVM would draw a boundary separating these data points.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import svm\n\n# Generate some sample data\nnp.random.seed(0)\n# Red points in Quadrant 1\nX_red = np.random.randn(10, 2) * 0.4 + [2, 2]\n# Green points in Quadrant 3\nX_green = np.random.randn(10, 2) * 0.4 + [-2, -2]\n\nX = np.vstack((X_red, X_green))\ny = np.array([0]*10 + [1]*10)  # 0: red, 1: green\n\n# Fit the SVM model\nclf = svm.SVC(kernel='linear')\nclf.fit(X, y)\n\n# Create a mesh to plot the decision boundary\nxx, yy = np.meshgrid(np.linspace(-4, 4, 500), np.linspace(-4, 4, 500))\nZ = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n# Plot 1: just the points\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\nplt.scatter(X_red[:, 0], X_red[:, 1], c='red', label='Class 0 (Red)')\nplt.scatter(X_green[:, 0], X_green[:, 1], c='green', label='Class 1 (Green)')\nplt.title('Red and Green Points')\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.legend()\nplt.grid(True)\n\n# Plot 2: with decision boundary\nplt.subplot(1, 2, 2)\nplt.scatter(X_red[:, 0], X_red[:, 1], c='red')\nplt.scatter(X_green[:, 0], X_green[:, 1], c='green')\nplt.contour(xx, yy, Z, levels=[0], colors='blue', linewidths=2)\nplt.title('SVM Decision Boundary')\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIn two dimensions (like above), this is a simple line. In higher dimensions (like our 204-dimensional EEG data), this boundary is a plane or a hyperplane. What makes SVMs distinct is their strategy for finding this boundary: they aim to maximize the margin, which is the distance between the separating hyperplane and the closest data points from each class. These closest points are called “support vectors” because they essentially support or define the position of the margin and the hyperplane. This principle of maximizing the margin often leads to classifiers that generalize well to new, unseen data. While the underlying mathematics involves optimization, the core idea is finding this maximal-margin separator.\nSVMs are especially well-suited for the EEG data in this project. EEG data is inherently high-dimensional (given the number of electrodes), and SVMs are effective in such high-dimensional spaces, potentially mitigating the “curse of dimensionality” better than some other algorithms. They can perform well even when the number of training samples is close to the number of features (which is relevant for our project), because of the emphasis on maximizing the margin. This emphasis can also help to reduce the impact of noise on our classifier.\nSVMs have applications beyond BCI and neuroscience. They’ve been used to classify text in various ways (such as detecting spam emails) (cite: support vector machine active learning), detect faces (cite: face recognition) and even predict geological events (cite: seismic events). As we can see, this technology is widely applicable, and its continued study has many potential benefits."
  },
  {
    "objectID": "index.html#data-acquisition",
    "href": "index.html#data-acquisition",
    "title": "Brain-Computer Interface Movement Decoding",
    "section": "2.1 Data Acquisition",
    "text": "2.1 Data Acquisition\nThe foundation of this project is the electroencephalography (EEG) data collected from a human subject.\n\nEEG Setup: The specific setup used for this data involved 102 electrodes distributed across the scalp, as seen below (with each blue point being a single electrode). Each electrode measured information related to the local electrical field gradient, providing two distinct data components (one for the x-direction gradient, one for the y-direction gradient). This resulted in a total of 204 data channels or features for each recorded time point or trial.\n\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndf = pd.read_csv(\"assets/BCIsensor_xy.csv\", header=None)\nx = df.iloc[:, 0]\ny = df.iloc[:, 1]\nplt.plot(x, y)\nplt.scatter(x, y, color=\"blue\", s=20, zorder=3)\nfor i, (xi, yi) in enumerate(zip(x, y)):\n        plt.text(xi, yi, str(i + 1), fontsize=8, ha='right', va='bottom')\nplt.axis(\"equal\")\nplt.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\nExperimental Conditions: Data was collected under two distinct conditions:\n\nOvert Movement: The subject physically moved their left or right arm. Signals recorded during overt movement are expected to be stronger and potentially easier to classify.\nImagined Movement: The subject imagined moving their left or right arm but remained physically still. These signals are typically weaker but are very important for BCIs designed for individuals who cannot perform physical movements.\n\nData Structure: For each condition (Overt and Imagined), the dataset contains 120 trials corresponding to “movement 1” and 120 trials corresponding to “movement 2”. The specific mapping of “movement 1” and “movement 2” to the actual left or right hand movement is unknown for this dataset. This gives a total of 240 trials per condition, with each individual trial represented as a 204-dimensional feature vector, corresponding to the measurements from the 204 data channels. For classification, we treat this as a binary problem distinguishing between the two movement types."
  },
  {
    "objectID": "index.html#classification-with-support-vector-machines-svms",
    "href": "index.html#classification-with-support-vector-machines-svms",
    "title": "Brain-Computer Interface Movement Decoding",
    "section": "2.2 Classification with Support Vector Machines (SVMs)",
    "text": "2.2 Classification with Support Vector Machines (SVMs)\nBefore we look at the results of our classifier, let’s understand what’s happening under the hood. Remember that the core task of the SVM classifier in this project is to learn a decision boundary that separates the two classes of movement intention (Movement 1 vs. Movement 2) based on the 204-dimensional EEG feature vectors.\n\n2.2.1 Mathematical Formulation\nLet our training dataset consist of \\(N\\) trials, where each trial \\(i\\) has a feature vector \\(x_i \\in \\mathbb{R}^{204}\\) and a corresponding class label \\(y_i \\in \\{-1, +1\\}\\) (representing, for example, Movement 1 and Movement 2). The goal of the linear SVM is to find the optimal separating hyperplane defined by a weight vector \\(w\\) and a bias term \\(b\\). The hyperplane equation is \\(w^T x + b = 0\\).\nBut what happens if the data overlaps, or if the true boundary between classes isn’t a straight line? In such cases, no single linear hyperplane can perfectly separate all the data points. To handle potential overlap and non-separability even in the linear case, we use the soft-margin SVM formulation. This approach seeks a hyperplane that balances maximizing the margin between the classes and minimizing the number of classification errors, allowing some data points to be misclassified or fall within the margin boundary. This is achieved by solving the following optimization problem (cite: support vector machines, author is mammon):\n\\[\n\\min_{w, b, \\xi} \\frac{1}{2} w^T w + C \\sum_{i=1}^{N} \\xi_i\n\\]\nsubject to the constraints:\n\\[\ny_i (w^T x_i + b) \\ge 1 - \\xi_i, \\quad \\text{for } i = 1, \\dots, N\n\\] \\[\n\\xi_i \\ge 0, \\quad \\text{for } i = 1, \\dots, N\n\\]\nTerms:\n\n\\(w\\): The weight vector, which is perpendicular to the separating hyperplane. Its magnitude \\(||w|| = \\sqrt{w^T w}\\) is inversely related to the margin width. Minimizing \\(\\frac{1}{2} w^T w\\) is equivalent to maximizing the margin (\\(2/||w||\\)).\n\\(b\\): The bias term, which shifts the hyperplane parallel to itself without changing its orientation.\n\\(x_i\\): The 204-dimensional feature vector for the \\(i\\)-th training trial.\n\\(y_i\\): The class label (+1 or -1) for the \\(i\\)-th training trial.\n\\(\\xi_i\\): These are non-negative slack variables. \\(\\xi_i\\) represents the degree to which the \\(i\\)-th data point violates the margin constraint. If \\(\\xi_i = 0\\), the point is correctly classified and on or outside its correct margin boundary. If \\(0 &lt; \\xi_i \\le 1\\), the point is correctly classified but falls within the margin. If \\(\\xi_i &gt; 1\\), the point is misclassified.\n\\(C\\): This is the regularization parameter. Note: in our class slides we present a slightly different, but equivalent formulation, of the SVM. In this formulation, \\(C = 1 / \\alpha\\). It controls the trade-off between maximizing the margin (associated with term \\(\\frac{1}{2} w^T w\\)) and minimizing the classification errors (associated with term \\(C \\sum \\xi_i\\)).\n\nA large \\(C\\) imposes a high cost on misclassifications (\\(\\xi_i &gt; 0\\)), pushing the SVM to fit the training data more closely, potentially leading to a smaller margin and risking overfitting.\nA small \\(C\\) imposes a lower cost on misclassifications, allowing for a wider margin even if more training points are misclassified or within the margin, which may improve generalization but risks underfitting. Finding an appropriate value for \\(C\\) is crucial for the performance of our model and will be done through cross-validation, which is explained further on.\n\n\nOptimization Problem Type:\nThis mathematical formulation constitutes what we call a convex optimization problem. A convex optimization problem is a problem in which every local minimum is also a global minimum. Generally, a function is convex if it satisfies the following: \\(f(\\lambda x_1 + (1 - \\lambda)x_2) \\leq \\lambda f(x_1) + (1 - \\lambda)f(x_2), \\quad \\forall x_1, x_2, \\lambda \\in [0,1]\\). Basically, imagine a bowl curving upwards. To be a convex optimization problem, both the function to be minimized and the constraints we apply to that function must be convex, which, examining our formulation for the SVM, is satisfied. To be more formal, we require (cite mlss2011): 1. The objective function term \\(\\frac{1}{2} w^T w\\) is quadratic in \\(w\\) and thus convex. 2. The term \\(C \\sum \\xi_i\\) is linear in \\(\\xi\\) and thus convex. 3. The sum of these two convex terms results in a convex overall objective function. 4. The constraints \\(y_i (w^T x_i + b) \\ge 1 - \\xi_i\\) and \\(\\xi_i \\ge 0\\) are all linear inequalities in \\(w, b, \\xi\\). Linear inequalities define convex feasible regions (specifically, half-spaces), and the intersection of convex sets is also convex.\nBecause both the objective function and the feasible region are convex, the entire problem is convex. The convexity of this problem helps ensure that standard optimization algorithms can find a unique optimal solution for the hyperplane.\n\n\n2.2.2 Handling Non-Linearity: The Kernel Trick\nThe linear SVM formulation described above finds a linear boundary. However, in many real-world problems, the relationship between features and classes might be non-linear, meaning a straight line or flat plane isn’t enough to separate the classes effectively. SVMs can handle this using kernels.\nThe core idea, often called the “kernel trick,” is to implicitly map the original input features \\(x_i\\) into a much higher-dimensional space using a mapping function \\(\\phi(x)\\) (cite: improving support vector machines). In this higher-dimensional space, the data might become linearly separable, allowing us to find a linear hyperplane there. The “trick” is that we don’t need to explicitly compute the high-dimensional coordinates \\(\\phi(x_i)\\). Instead, kernel functions \\(K(x_i, x_j)\\) compute the dot product of the mapped vectors directly: \\(K(x_i, x_j) = \\phi(x_i)^T \\phi(x_j)\\). Since the SVM algorithm’s solution primarily depends on dot products between feature vectors (especially in its dual formulation), we can substitute \\(x_i^T x_j\\) with \\(K(x_i, x_j)\\) everywhere, which lets us perform the classification in the high-dimensional space without the extra computational cost of transforming the data.\nCommon Kernels: The baseline for this project is the linear kernel (\\(K(x_i, x_j) = x_i^T x_j\\)). However, I experimented with two other kernels to see their performance, specifically:\n\nPolynomial Kernel: \\(K(x_i, x_j) = (\\gamma x_i^T x_j + r)^d\\). This kernel can model polynomial boundaries, and introduces hyperparameters: the degree \\(d\\), a scaling factor \\(\\gamma\\), and a coefficient \\(r\\) (cite: the kernel polynomial method).\nRadial Basis Function (RBF) Kernel (Gaussian Kernel): \\(K(x_i, x_j) = \\exp(-\\gamma ||x_i - x_j||^2)\\). This kernel is also capable of modeling complex boundaries. Its behavior is controlled by the hyperparameter \\(\\gamma\\), which defines how far the influence of a single training example reaches. A small \\(\\gamma\\) means a broader influence (smoother boundary), while a large \\(\\gamma\\) means a more localized influence (potentially wigglier boundary, risk of overfitting) (cite: parameter selection in…). Maybe visualization, 2D illustration of an SVM hyperplane, margin, and support vectors"
  }
]